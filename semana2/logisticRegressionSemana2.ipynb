{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDb Movie Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a simple logistic regression model to classify movie reviews from the 50k IMDb review dataset that has been collected by Maas et. al.\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142â€“150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]\n",
    "\n",
    "The dataset consists of 50,000 movie reviews from the original \"train\" and \"test\" subdirectories. The class labels are binary (1=positive and 0=negative) and contain 25,000 positive and 25,000 negative movie reviews, respectively.\n",
    "For simplicity, I assembled the reviews in a single CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# if you want to download the original file:\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/50k_imdb_movie_reviews.csv')\n",
    "# otherwise load local file\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## uncomment these lines if you have dowloaded the original file:\n",
    "#np.random.seed(0)\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df[['review', 'sentiment']].to_csv('shuffled_movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a simple `tokenizer` that splits the text into individual word tokens. Furthermore, we will use some simple regular expression to remove HTML markup and all non-letter characters but \"emoticons,\" convert the text to lower case, remove stopwords, and apply the Porter stemming algorithm to convert the words into their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    text = [w for w in text.split() if w not in stop]\n",
    "    tokenized = [porter.stem(w) for w in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it at try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', ':)', ':)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('This :) is a <a> test! :-)</br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning (SciKit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a generator that returns the document body and the corresponding class label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conform that the `stream_docs` function fetches the documents as intended, let us execute the following code snippet before we implement the `get_minibatch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
       " 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path='shuffled_movie_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we confirmed that our `stream_docs` functions works, we will now implement a `get_minibatch` function to fetch a specified number (`size`) of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    for _ in range(size):\n",
    "        text, label = next(doc_stream)\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make use of the \"hashing trick\" through scikit-learns [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html) to create a bag-of-words model of our documents. Details of the bag-of-words model for document classification can be found at  [Naive Bayes and Text Classification I - Introduction and Theory](http://arxiv.org/abs/1410.5329)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "# Excercise 1: define new features according this https://web.stanford.edu/~jurafsky/slp3/7.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Las nuevas caracteristicas de agregan en el tokenizer\n",
    "def tokenizer2(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    text = [w for w in text.split() if w not in stop]\n",
    "    tokenized = [porter.stem(w) for w in text]\n",
    "    return tokenized # trabajamos solamente con raices de las palabras ,eg run ,running = run\n",
    "\n",
    "vect2 = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [SGDClassifier]() from scikit-learn, we will can instanciate a logistic regression classifier that learns from the documents incrementally using stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "clf2 = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path='shuffled_movie_data.csv')\n",
    "# Excercise 2: implement a MaxEnt classifier, using regularization, according this https://web.stanford.edu/~jurafsky/slp3/7.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 MaxEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ejercicio 2 : implementacion MaxEnt\n",
    "class MaximunEntropy():\n",
    "    def __init__(self, learning_rate = 0.5, max_iter = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.theta = []\n",
    "        self.no_examples = 0\n",
    "        self.no_features = 0\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "    # add bias a la columna 0 de la matriz X\n",
    "    def add_bias_col_X(self, X):\n",
    "        bias_col = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate([bias_col, X], axis=1)\n",
    "    # usamos la funcion sigmoidea\n",
    "    def hypothesis(self, X):\n",
    "        return 1 / (1 + np.exp(-1.0 * np.dot(X, self.theta)))\n",
    " \n",
    "    def cost_function(self):\n",
    "        predicted_Y_values = self.hypothesis(self.X)\n",
    "        cost = (-1.0/self.no_examples) * np.sum(self.Y * np.log(predicted_Y_values) + (1 - self.Y) * (np.log(1-predicted_Y_values)))\n",
    "        return cost\n",
    "        \n",
    "    def gradient(self):\n",
    "        predicted_Y_values = self.hypothesis(self.X)\n",
    "        grad = (-1.0/self.no_examples) * np.dot((self.Y-predicted_Y_values), self.X)\n",
    "        return grad\n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        for iter in range(1,self.max_iter):\n",
    "            cost = self.cost_function()\n",
    "            delta = self.gradient()\n",
    "            self.theta = self.theta - self.learning_rate * delta\n",
    "            print(\"iteracion %s : costo %s \" % (iter, cost))\n",
    "    def train(self,X,Y):\n",
    "        self.X = self.add_bias_col_X(X)\n",
    "        self.Y = Y\n",
    "        self.no_examples, self.no_features = np.shape(X)\n",
    "        self.theta = np.ones(self.no_features + 1)\n",
    "        self.gradient_descent()\n",
    "    def classify(self,X):\n",
    "        X = self.add_bias_col_X(X)\n",
    "        predicted_Y = self.hypothesis(X)\n",
    "        predicted_Y_binary = np.round(predicted_Y)\n",
    "        return predicted_Y_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usando MaxEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracion 1 : costo 0.799848333838 \n",
      "iteracion 2 : costo 0.789439191647 \n",
      "iteracion 3 : costo 0.780979758463 \n",
      "iteracion 4 : costo 0.773922606949 \n",
      "iteracion 5 : costo 0.767870467274 \n",
      "iteracion 6 : costo 0.7625375958 \n",
      "iteracion 7 : costo 0.757719773531 \n",
      "iteracion 8 : costo 0.753271712847 \n",
      "iteracion 9 : costo 0.749090390405 \n",
      "iteracion 10 : costo 0.745102923916 \n",
      "iteracion 11 : costo 0.741257839921 \n",
      "iteracion 12 : costo 0.737518827112 \n",
      "iteracion 13 : costo 0.733860289445 \n",
      "iteracion 14 : costo 0.730264191517 \n",
      "iteracion 15 : costo 0.726717826345 \n",
      "iteracion 16 : costo 0.723212238751 \n",
      "iteracion 17 : costo 0.719741113359 \n",
      "iteracion 18 : costo 0.716299991107 \n",
      "iteracion 19 : costo 0.712885717664 \n",
      "iteracion 20 : costo 0.70949605537 \n",
      "iteracion 21 : costo 0.706129410364 \n",
      "iteracion 22 : costo 0.70278464078 \n",
      "iteracion 23 : costo 0.699460921995 \n",
      "iteracion 24 : costo 0.696157651971 \n",
      "iteracion 25 : costo 0.692874384793 \n",
      "iteracion 26 : costo 0.689610784013 \n",
      "iteracion 27 : costo 0.6863665899 \n",
      "iteracion 28 : costo 0.683141596464 \n",
      "iteracion 29 : costo 0.679935635338 \n",
      "iteracion 30 : costo 0.676748564466 \n",
      "iteracion 31 : costo 0.67358026018 \n",
      "iteracion 32 : costo 0.670430611634 \n",
      "iteracion 33 : costo 0.667299516914 \n",
      "iteracion 34 : costo 0.664186880303 \n",
      "iteracion 35 : costo 0.661092610367 \n",
      "iteracion 36 : costo 0.658016618618 \n",
      "iteracion 37 : costo 0.654958818575 \n",
      "iteracion 38 : costo 0.651919125107 \n",
      "iteracion 39 : costo 0.648897453978 \n",
      "iteracion 40 : costo 0.645893721525 \n",
      "iteracion 41 : costo 0.642907844438 \n",
      "iteracion 42 : costo 0.639939739603 \n",
      "iteracion 43 : costo 0.636989324001 \n",
      "iteracion 44 : costo 0.634056514631 \n",
      "iteracion 45 : costo 0.631141228463 \n",
      "iteracion 46 : costo 0.628243382408 \n",
      "iteracion 47 : costo 0.625362893292 \n",
      "iteracion 48 : costo 0.622499677852 \n",
      "iteracion 49 : costo 0.619653652719 \n",
      "iteracion 50 : costo 0.616824734426 \n",
      "iteracion 51 : costo 0.614012839401 \n",
      "iteracion 52 : costo 0.611217883974 \n",
      "iteracion 53 : costo 0.608439784376 \n",
      "iteracion 54 : costo 0.605678456751 \n",
      "iteracion 55 : costo 0.602933817155 \n",
      "iteracion 56 : costo 0.600205781567 \n",
      "iteracion 57 : costo 0.597494265892 \n",
      "iteracion 58 : costo 0.59479918597 \n",
      "iteracion 59 : costo 0.592120457584 \n",
      "iteracion 60 : costo 0.589457996463 \n",
      "iteracion 61 : costo 0.586811718294 \n",
      "iteracion 62 : costo 0.584181538728 \n",
      "iteracion 63 : costo 0.581567373385 \n",
      "iteracion 64 : costo 0.578969137865 \n",
      "iteracion 65 : costo 0.576386747751 \n",
      "iteracion 66 : costo 0.573820118623 \n",
      "iteracion 67 : costo 0.571269166059 \n",
      "iteracion 68 : costo 0.568733805646 \n",
      "iteracion 69 : costo 0.566213952984 \n",
      "iteracion 70 : costo 0.5637095237 \n",
      "iteracion 71 : costo 0.561220433448 \n",
      "iteracion 72 : costo 0.55874659792 \n",
      "iteracion 73 : costo 0.556287932853 \n",
      "iteracion 74 : costo 0.553844354036 \n",
      "iteracion 75 : costo 0.551415777317 \n",
      "iteracion 76 : costo 0.549002118611 \n",
      "iteracion 77 : costo 0.546603293905 \n",
      "iteracion 78 : costo 0.544219219269 \n",
      "iteracion 79 : costo 0.541849810857 \n",
      "iteracion 80 : costo 0.539494984921 \n",
      "iteracion 81 : costo 0.537154657811 \n",
      "iteracion 82 : costo 0.534828745988 \n",
      "iteracion 83 : costo 0.532517166026 \n",
      "iteracion 84 : costo 0.530219834621 \n",
      "iteracion 85 : costo 0.527936668598 \n",
      "iteracion 86 : costo 0.525667584917 \n",
      "iteracion 87 : costo 0.523412500677 \n",
      "iteracion 88 : costo 0.521171333127 \n",
      "iteracion 89 : costo 0.518943999669 \n",
      "iteracion 90 : costo 0.516730417867 \n",
      "iteracion 91 : costo 0.514530505448 \n",
      "iteracion 92 : costo 0.512344180314 \n",
      "iteracion 93 : costo 0.510171360547 \n",
      "iteracion 94 : costo 0.50801196441 \n",
      "iteracion 95 : costo 0.505865910358 \n",
      "iteracion 96 : costo 0.503733117044 \n",
      "iteracion 97 : costo 0.50161350332 \n",
      "iteracion 98 : costo 0.499506988247 \n",
      "iteracion 99 : costo 0.497413491098 \n",
      "batch  0\n",
      "iteracion 1 : costo 0.837799639227 \n",
      "iteracion 2 : costo 0.833369233705 \n",
      "iteracion 3 : costo 0.829060495326 \n",
      "iteracion 4 : costo 0.824845058859 \n",
      "iteracion 5 : costo 0.820702571045 \n",
      "iteracion 6 : costo 0.816618445693 \n",
      "iteracion 7 : costo 0.812582237765 \n",
      "iteracion 8 : costo 0.808586469926 \n",
      "iteracion 9 : costo 0.804625788078 \n",
      "iteracion 10 : costo 0.800696355042 \n",
      "iteracion 11 : costo 0.796795416087 \n",
      "iteracion 12 : costo 0.79292098808 \n",
      "iteracion 13 : costo 0.789071637408 \n",
      "iteracion 14 : costo 0.785246321494 \n",
      "iteracion 15 : costo 0.781444275809 \n",
      "iteracion 16 : costo 0.777664933403 \n",
      "iteracion 17 : costo 0.773907867632 \n",
      "iteracion 18 : costo 0.770172751421 \n",
      "iteracion 19 : costo 0.76645932832 \n",
      "iteracion 20 : costo 0.762767391929 \n",
      "iteracion 21 : costo 0.759096771306 \n",
      "iteracion 22 : costo 0.755447320599 \n",
      "iteracion 23 : costo 0.751818911698 \n",
      "iteracion 24 : costo 0.748211429026 \n",
      "iteracion 25 : costo 0.744624765839 \n",
      "iteracion 26 : costo 0.741058821617 \n",
      "iteracion 27 : costo 0.737513500201 \n",
      "iteracion 28 : costo 0.733988708489 \n",
      "iteracion 29 : costo 0.730484355502 \n",
      "iteracion 30 : costo 0.72700035173 \n",
      "iteracion 31 : costo 0.723536608663 \n",
      "iteracion 32 : costo 0.720093038468 \n",
      "iteracion 33 : costo 0.716669553753 \n",
      "iteracion 34 : costo 0.713266067407 \n",
      "iteracion 35 : costo 0.709882492483 \n",
      "iteracion 36 : costo 0.706518742116 \n",
      "iteracion 37 : costo 0.70317472947 \n",
      "iteracion 38 : costo 0.699850367697 \n",
      "iteracion 39 : costo 0.696545569909 \n",
      "iteracion 40 : costo 0.693260249164 \n",
      "iteracion 41 : costo 0.689994318448 \n",
      "iteracion 42 : costo 0.68674769067 \n",
      "iteracion 43 : costo 0.683520278659 \n",
      "iteracion 44 : costo 0.680311995159 \n",
      "iteracion 45 : costo 0.677122752832 \n",
      "iteracion 46 : costo 0.673952464252 \n",
      "iteracion 47 : costo 0.670801041913 \n",
      "iteracion 48 : costo 0.667668398227 \n",
      "iteracion 49 : costo 0.664554445528 \n",
      "iteracion 50 : costo 0.661459096073 \n",
      "iteracion 51 : costo 0.658382262049 \n",
      "iteracion 52 : costo 0.655323855571 \n",
      "iteracion 53 : costo 0.652283788689 \n",
      "iteracion 54 : costo 0.64926197339 \n",
      "iteracion 55 : costo 0.646258321603 \n",
      "iteracion 56 : costo 0.643272745203 \n",
      "iteracion 57 : costo 0.640305156011 \n",
      "iteracion 58 : costo 0.637355465805 \n",
      "iteracion 59 : costo 0.634423586318 \n",
      "iteracion 60 : costo 0.631509429245 \n",
      "iteracion 61 : costo 0.628612906247 \n",
      "iteracion 62 : costo 0.625733928955 \n",
      "iteracion 63 : costo 0.622872408976 \n",
      "iteracion 64 : costo 0.620028257893 \n",
      "iteracion 65 : costo 0.617201387276 \n",
      "iteracion 66 : costo 0.614391708684 \n",
      "iteracion 67 : costo 0.611599133667 \n",
      "iteracion 68 : costo 0.608823573775 \n",
      "iteracion 69 : costo 0.60606494056 \n",
      "iteracion 70 : costo 0.603323145584 \n",
      "iteracion 71 : costo 0.60059810042 \n",
      "iteracion 72 : costo 0.597889716662 \n",
      "iteracion 73 : costo 0.595197905925 \n",
      "iteracion 74 : costo 0.592522579855 \n",
      "iteracion 75 : costo 0.58986365013 \n",
      "iteracion 76 : costo 0.587221028469 \n",
      "iteracion 77 : costo 0.584594626637 \n",
      "iteracion 78 : costo 0.581984356446 \n",
      "iteracion 79 : costo 0.579390129767 \n",
      "iteracion 80 : costo 0.576811858531 \n",
      "iteracion 81 : costo 0.574249454735 \n",
      "iteracion 82 : costo 0.571702830452 \n",
      "iteracion 83 : costo 0.569171897829 \n",
      "iteracion 84 : costo 0.566656569101 \n",
      "iteracion 85 : costo 0.564156756589 \n",
      "iteracion 86 : costo 0.561672372711 \n",
      "iteracion 87 : costo 0.559203329988 \n",
      "iteracion 88 : costo 0.556749541044 \n",
      "iteracion 89 : costo 0.554310918619 \n",
      "iteracion 90 : costo 0.551887375571 \n",
      "iteracion 91 : costo 0.549478824879 \n",
      "iteracion 92 : costo 0.547085179657 \n",
      "iteracion 93 : costo 0.544706353152 \n",
      "iteracion 94 : costo 0.542342258752 \n",
      "iteracion 95 : costo 0.539992809994 \n",
      "iteracion 96 : costo 0.537657920568 \n",
      "iteracion 97 : costo 0.535337504322 \n",
      "iteracion 98 : costo 0.533031475269 \n",
      "iteracion 99 : costo 0.530739747594 \n",
      "batch  1\n",
      "iteracion 1 : costo 0.770726982111 \n",
      "iteracion 2 : costo 0.761666499379 \n",
      "iteracion 3 : costo 0.75407732013 \n",
      "iteracion 4 : costo 0.74754665831 \n",
      "iteracion 5 : costo 0.741775953038 \n",
      "iteracion 6 : costo 0.736551168047 \n",
      "iteracion 7 : costo 0.731719861327 \n",
      "iteracion 8 : costo 0.727173979112 \n",
      "iteracion 9 : costo 0.722837197182 \n",
      "iteracion 10 : costo 0.718655736414 \n",
      "iteracion 11 : costo 0.714591765336 \n",
      "iteracion 12 : costo 0.710618695355 \n",
      "iteracion 13 : costo 0.706717843652 \n",
      "iteracion 14 : costo 0.70287607565 \n",
      "iteracion 15 : costo 0.699084144548 \n",
      "iteracion 16 : costo 0.695335524555 \n",
      "iteracion 17 : costo 0.691625592512 \n",
      "iteracion 18 : costo 0.687951054687 \n",
      "iteracion 19 : costo 0.684309545773 \n",
      "iteracion 20 : costo 0.680699348591 \n",
      "iteracion 21 : costo 0.677119198338 \n",
      "iteracion 22 : costo 0.673568145944 \n",
      "iteracion 23 : costo 0.670045462758 \n",
      "iteracion 24 : costo 0.666550574083 \n",
      "iteracion 25 : costo 0.663083012847 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracion 26 : costo 0.659642387329 \n",
      "iteracion 27 : costo 0.656228358667 \n",
      "iteracion 28 : costo 0.652840625208 \n",
      "iteracion 29 : costo 0.649478911605 \n",
      "iteracion 30 : costo 0.646142961229 \n",
      "iteracion 31 : costo 0.642832530891 \n",
      "iteracion 32 : costo 0.639547387172 \n",
      "iteracion 33 : costo 0.636287303866 \n",
      "iteracion 34 : costo 0.633052060208 \n",
      "iteracion 35 : costo 0.629841439636 \n",
      "iteracion 36 : costo 0.626655228942 \n",
      "iteracion 37 : costo 0.623493217671 \n",
      "iteracion 38 : costo 0.620355197711 \n",
      "iteracion 39 : costo 0.617240963011 \n",
      "iteracion 40 : costo 0.614150309379 \n",
      "iteracion 41 : costo 0.61108303435 \n",
      "iteracion 42 : costo 0.608038937091 \n",
      "iteracion 43 : costo 0.605017818335 \n",
      "iteracion 44 : costo 0.602019480343 \n",
      "iteracion 45 : costo 0.599043726867 \n",
      "iteracion 46 : costo 0.596090363136 \n",
      "iteracion 47 : costo 0.593159195838 \n",
      "iteracion 48 : costo 0.590250033113 \n",
      "iteracion 49 : costo 0.587362684549 \n",
      "iteracion 50 : costo 0.584496961172 \n",
      "iteracion 51 : costo 0.581652675448 \n",
      "iteracion 52 : costo 0.578829641281 \n",
      "iteracion 53 : costo 0.576027674007 \n",
      "iteracion 54 : costo 0.573246590396 \n",
      "iteracion 55 : costo 0.570486208649 \n",
      "iteracion 56 : costo 0.567746348397 \n",
      "iteracion 57 : costo 0.565026830696 \n",
      "iteracion 58 : costo 0.562327478031 \n",
      "iteracion 59 : costo 0.559648114308 \n",
      "iteracion 60 : costo 0.556988564852 \n",
      "iteracion 61 : costo 0.554348656407 \n",
      "iteracion 62 : costo 0.551728217131 \n",
      "iteracion 63 : costo 0.54912707659 \n",
      "iteracion 64 : costo 0.546545065761 \n",
      "iteracion 65 : costo 0.543982017018 \n",
      "iteracion 66 : costo 0.541437764138 \n",
      "iteracion 67 : costo 0.538912142288 \n",
      "iteracion 68 : costo 0.536404988027 \n",
      "iteracion 69 : costo 0.533916139295 \n",
      "iteracion 70 : costo 0.531445435411 \n",
      "iteracion 71 : costo 0.528992717068 \n",
      "iteracion 72 : costo 0.526557826324 \n",
      "iteracion 73 : costo 0.5241406066 \n",
      "iteracion 74 : costo 0.52174090267 \n",
      "iteracion 75 : costo 0.519358560658 \n",
      "iteracion 76 : costo 0.516993428031 \n",
      "iteracion 77 : costo 0.514645353589 \n",
      "iteracion 78 : costo 0.512314187463 \n",
      "iteracion 79 : costo 0.509999781104 \n",
      "iteracion 80 : costo 0.507701987278 \n",
      "iteracion 81 : costo 0.50542066006 \n",
      "iteracion 82 : costo 0.503155654822 \n",
      "iteracion 83 : costo 0.500906828231 \n",
      "iteracion 84 : costo 0.498674038238 \n",
      "iteracion 85 : costo 0.496457144071 \n",
      "iteracion 86 : costo 0.494256006228 \n",
      "iteracion 87 : costo 0.492070486467 \n",
      "iteracion 88 : costo 0.489900447801 \n",
      "iteracion 89 : costo 0.487745754487 \n",
      "iteracion 90 : costo 0.485606272021 \n",
      "iteracion 91 : costo 0.483481867127 \n",
      "iteracion 92 : costo 0.481372407749 \n",
      "iteracion 93 : costo 0.479277763045 \n",
      "iteracion 94 : costo 0.477197803375 \n",
      "iteracion 95 : costo 0.475132400295 \n",
      "iteracion 96 : costo 0.47308142655 \n",
      "iteracion 97 : costo 0.471044756061 \n",
      "iteracion 98 : costo 0.46902226392 \n",
      "iteracion 99 : costo 0.467013826379 \n",
      "batch  2\n",
      "iteracion 1 : costo 0.663432146333 \n",
      "iteracion 2 : costo 0.657874185935 \n",
      "iteracion 3 : costo 0.653009096687 \n",
      "iteracion 4 : costo 0.648636254853 \n",
      "iteracion 5 : costo 0.644614531992 \n",
      "iteracion 6 : costo 0.640844925961 \n",
      "iteracion 7 : costo 0.637258107669 \n",
      "iteracion 8 : costo 0.633805575508 \n",
      "iteracion 9 : costo 0.63045341184 \n",
      "iteracion 10 : costo 0.627177894848 \n",
      "iteracion 11 : costo 0.623962423268 \n",
      "iteracion 12 : costo 0.620795365355 \n",
      "iteracion 13 : costo 0.61766855627 \n",
      "iteracion 14 : costo 0.61457624931 \n",
      "iteracion 15 : costo 0.611514384301 \n",
      "iteracion 16 : costo 0.608480077424 \n",
      "iteracion 17 : costo 0.605471265507 \n",
      "iteracion 18 : costo 0.602486458051 \n",
      "iteracion 19 : costo 0.599524564361 \n",
      "iteracion 20 : costo 0.596584773028 \n",
      "iteracion 21 : costo 0.593666467908 \n",
      "iteracion 22 : costo 0.590769169532 \n",
      "iteracion 23 : costo 0.587892494257 \n",
      "iteracion 24 : costo 0.585036125769 \n",
      "iteracion 25 : costo 0.582199795203 \n",
      "iteracion 26 : costo 0.579383267278 \n",
      "iteracion 27 : costo 0.576586330614 \n",
      "iteracion 28 : costo 0.573808790976 \n",
      "iteracion 29 : costo 0.571050466552 \n",
      "iteracion 30 : costo 0.568311184653 \n",
      "iteracion 31 : costo 0.565590779406 \n",
      "iteracion 32 : costo 0.562889090139 \n",
      "iteracion 33 : costo 0.560205960246 \n",
      "iteracion 34 : costo 0.557541236395 \n",
      "iteracion 35 : costo 0.554894767964 \n",
      "iteracion 36 : costo 0.552266406643 \n",
      "iteracion 37 : costo 0.549656006158 \n",
      "iteracion 38 : costo 0.547063422065 \n",
      "iteracion 39 : costo 0.544488511607 \n",
      "iteracion 40 : costo 0.541931133606 \n",
      "iteracion 41 : costo 0.539391148384 \n",
      "iteracion 42 : costo 0.536868417706 \n",
      "iteracion 43 : costo 0.53436280473 \n",
      "iteracion 44 : costo 0.531874173973 \n",
      "iteracion 45 : costo 0.529402391279 \n",
      "iteracion 46 : costo 0.526947323793 \n",
      "iteracion 47 : costo 0.524508839941 \n",
      "iteracion 48 : costo 0.522086809407 \n",
      "iteracion 49 : costo 0.519681103116 \n",
      "iteracion 50 : costo 0.517291593218 \n",
      "iteracion 51 : costo 0.51491815307 \n",
      "iteracion 52 : costo 0.51256065722 \n",
      "iteracion 53 : costo 0.510218981394 \n",
      "iteracion 54 : costo 0.507893002481 \n",
      "iteracion 55 : costo 0.505582598513 \n",
      "iteracion 56 : costo 0.503287648661 \n",
      "iteracion 57 : costo 0.501008033211 \n",
      "iteracion 58 : costo 0.498743633557 \n",
      "iteracion 59 : costo 0.496494332183 \n",
      "iteracion 60 : costo 0.494260012653 \n",
      "iteracion 61 : costo 0.492040559595 \n",
      "iteracion 62 : costo 0.489835858689 \n",
      "iteracion 63 : costo 0.487645796656 \n",
      "iteracion 64 : costo 0.48547026124 \n",
      "iteracion 65 : costo 0.4833091412 \n",
      "iteracion 66 : costo 0.481162326297 \n",
      "iteracion 67 : costo 0.479029707278 \n",
      "iteracion 68 : costo 0.47691117587 \n",
      "iteracion 69 : costo 0.47480662476 \n",
      "iteracion 70 : costo 0.472715947591 \n",
      "iteracion 71 : costo 0.470639038944 \n",
      "iteracion 72 : costo 0.46857579433 \n",
      "iteracion 73 : costo 0.466526110178 \n",
      "iteracion 74 : costo 0.464489883822 \n",
      "iteracion 75 : costo 0.462467013493 \n",
      "iteracion 76 : costo 0.460457398304 \n",
      "iteracion 77 : costo 0.458460938241 \n",
      "iteracion 78 : costo 0.456477534156 \n",
      "iteracion 79 : costo 0.454507087748 \n",
      "iteracion 80 : costo 0.452549501562 \n",
      "iteracion 81 : costo 0.450604678973 \n",
      "iteracion 82 : costo 0.448672524177 \n",
      "iteracion 83 : costo 0.446752942181 \n",
      "iteracion 84 : costo 0.444845838796 \n",
      "iteracion 85 : costo 0.442951120622 \n",
      "iteracion 86 : costo 0.441068695045 \n",
      "iteracion 87 : costo 0.439198470223 \n",
      "iteracion 88 : costo 0.437340355078 \n",
      "iteracion 89 : costo 0.435494259287 \n",
      "iteracion 90 : costo 0.433660093276 \n",
      "iteracion 91 : costo 0.431837768206 \n",
      "iteracion 92 : costo 0.43002719597 \n",
      "iteracion 93 : costo 0.428228289178 \n",
      "iteracion 94 : costo 0.426440961157 \n",
      "iteracion 95 : costo 0.424665125936 \n",
      "iteracion 96 : costo 0.422900698241 \n",
      "iteracion 97 : costo 0.421147593487 \n",
      "iteracion 98 : costo 0.41940572777 \n",
      "iteracion 99 : costo 0.41767501786 \n",
      "batch  3\n",
      "iteracion 1 : costo 0.841098779832 \n",
      "iteracion 2 : costo 0.827433808214 \n",
      "iteracion 3 : costo 0.816850150032 \n",
      "iteracion 4 : costo 0.808422338047 \n",
      "iteracion 5 : costo 0.80149746783 \n",
      "iteracion 6 : costo 0.795619177622 \n",
      "iteracion 7 : costo 0.790470307922 \n",
      "iteracion 8 : costo 0.785831192711 \n",
      "iteracion 9 : costo 0.781549981061 \n",
      "iteracion 10 : costo 0.777521801014 \n",
      "iteracion 11 : costo 0.773674249954 \n",
      "iteracion 12 : costo 0.769957339183 \n",
      "iteracion 13 : costo 0.766336544343 \n",
      "iteracion 14 : costo 0.762788009213 \n",
      "iteracion 15 : costo 0.759295237716 \n",
      "iteracion 16 : costo 0.755846812691 \n",
      "iteracion 17 : costo 0.752434822558 \n",
      "iteracion 18 : costo 0.749053775939 \n",
      "iteracion 19 : costo 0.745699852672 \n",
      "iteracion 20 : costo 0.742370386812 \n",
      "iteracion 21 : costo 0.739063509665 \n",
      "iteracion 22 : costo 0.735777903264 \n",
      "iteracion 23 : costo 0.732512630095 \n",
      "iteracion 24 : costo 0.729267015466 \n",
      "iteracion 25 : costo 0.726040566246 \n",
      "iteracion 26 : costo 0.722832914721 \n",
      "iteracion 27 : costo 0.719643779814 \n",
      "iteracion 28 : costo 0.716472940293 \n",
      "iteracion 29 : costo 0.713320216269 \n",
      "iteracion 30 : costo 0.710185456414 \n",
      "iteracion 31 : costo 0.707068529144 \n",
      "iteracion 32 : costo 0.703969316525 \n",
      "iteracion 33 : costo 0.700887710074 \n",
      "iteracion 34 : costo 0.69782360786 \n",
      "iteracion 35 : costo 0.694776912507 \n",
      "iteracion 36 : costo 0.691747529815 \n",
      "iteracion 37 : costo 0.688735367815 \n",
      "iteracion 38 : costo 0.685740336114 \n",
      "iteracion 39 : costo 0.682762345451 \n",
      "iteracion 40 : costo 0.679801307387 \n",
      "iteracion 41 : costo 0.676857134095 \n",
      "iteracion 42 : costo 0.673929738217 \n",
      "iteracion 43 : costo 0.671019032767 \n",
      "iteracion 44 : costo 0.668124931066 \n",
      "iteracion 45 : costo 0.665247346695 \n",
      "iteracion 46 : costo 0.662386193468 \n",
      "iteracion 47 : costo 0.659541385413 \n",
      "iteracion 48 : costo 0.656712836759 \n",
      "iteracion 49 : costo 0.653900461931 \n",
      "iteracion 50 : costo 0.651104175542 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracion 51 : costo 0.648323892396 \n",
      "iteracion 52 : costo 0.645559527487 \n",
      "iteracion 53 : costo 0.642810995996 \n",
      "iteracion 54 : costo 0.640078213297 \n",
      "iteracion 55 : costo 0.637361094958 \n",
      "iteracion 56 : costo 0.634659556742 \n",
      "iteracion 57 : costo 0.631973514609 \n",
      "iteracion 58 : costo 0.629302884723 \n",
      "iteracion 59 : costo 0.626647583449 \n",
      "iteracion 60 : costo 0.62400752736 \n",
      "iteracion 61 : costo 0.621382633237 \n",
      "iteracion 62 : costo 0.618772818072 \n",
      "iteracion 63 : costo 0.616177999075 \n",
      "iteracion 64 : costo 0.613598093671 \n",
      "iteracion 65 : costo 0.611033019504 \n",
      "iteracion 66 : costo 0.608482694442 \n",
      "iteracion 67 : costo 0.605947036579 \n",
      "iteracion 68 : costo 0.603425964236 \n",
      "iteracion 69 : costo 0.600919395966 \n",
      "iteracion 70 : costo 0.598427250552 \n",
      "iteracion 71 : costo 0.595949447016 \n",
      "iteracion 72 : costo 0.593485904616 \n",
      "iteracion 73 : costo 0.591036542853 \n",
      "iteracion 74 : costo 0.588601281468 \n",
      "iteracion 75 : costo 0.58618004045 \n",
      "iteracion 76 : costo 0.583772740036 \n",
      "iteracion 77 : costo 0.581379300711 \n",
      "iteracion 78 : costo 0.578999643215 \n",
      "iteracion 79 : costo 0.576633688542 \n",
      "iteracion 80 : costo 0.574281357942 \n",
      "iteracion 81 : costo 0.571942572928 \n",
      "iteracion 82 : costo 0.569617255269 \n",
      "iteracion 83 : costo 0.567305327004 \n",
      "iteracion 84 : costo 0.565006710433 \n",
      "iteracion 85 : costo 0.562721328126 \n",
      "iteracion 86 : costo 0.560449102925 \n",
      "iteracion 87 : costo 0.55818995794 \n",
      "iteracion 88 : costo 0.555943816558 \n",
      "iteracion 89 : costo 0.553710602442 \n",
      "iteracion 90 : costo 0.551490239532 \n",
      "iteracion 91 : costo 0.549282652049 \n",
      "iteracion 92 : costo 0.547087764494 \n",
      "iteracion 93 : costo 0.544905501654 \n",
      "iteracion 94 : costo 0.542735788599 \n",
      "iteracion 95 : costo 0.540578550689 \n",
      "iteracion 96 : costo 0.538433713571 \n",
      "iteracion 97 : costo 0.536301203182 \n",
      "iteracion 98 : costo 0.534180945752 \n",
      "iteracion 99 : costo 0.532072867806 \n",
      "batch  4\n",
      "iteracion 1 : costo 0.711811811538 \n",
      "iteracion 2 : costo 0.705925552609 \n",
      "iteracion 3 : costo 0.700783439768 \n",
      "iteracion 4 : costo 0.696183609864 \n",
      "iteracion 5 : costo 0.691979672041 \n",
      "iteracion 6 : costo 0.688065754177 \n",
      "iteracion 7 : costo 0.684365439215 \n",
      "iteracion 8 : costo 0.680823648537 \n",
      "iteracion 9 : costo 0.677400723042 \n",
      "iteracion 10 : costo 0.674068125399 \n",
      "iteracion 11 : costo 0.670805329119 \n",
      "iteracion 12 : costo 0.667597571783 \n",
      "iteracion 13 : costo 0.66443423509 \n",
      "iteracion 14 : costo 0.661307678309 \n",
      "iteracion 15 : costo 0.658212399014 \n",
      "iteracion 16 : costo 0.655144429728 \n",
      "iteracion 17 : costo 0.652100904418 \n",
      "iteracion 18 : costo 0.649079747172 \n",
      "iteracion 19 : costo 0.646079448703 \n",
      "iteracion 20 : costo 0.643098905974 \n",
      "iteracion 21 : costo 0.640137307131 \n",
      "iteracion 22 : costo 0.637194048986 \n",
      "iteracion 23 : costo 0.634268677847 \n",
      "iteracion 24 : costo 0.631360847103 \n",
      "iteracion 25 : costo 0.628470286824 \n",
      "iteracion 26 : costo 0.625596781984 \n",
      "iteracion 27 : costo 0.622740156855 \n",
      "iteracion 28 : costo 0.619900263839 \n",
      "iteracion 29 : costo 0.617076975464 \n",
      "iteracion 30 : costo 0.614270178658 \n",
      "iteracion 31 : costo 0.611479770654 \n",
      "iteracion 32 : costo 0.608705656057 \n",
      "iteracion 33 : costo 0.605947744746 \n",
      "iteracion 34 : costo 0.60320595038 \n",
      "iteracion 35 : costo 0.600480189324 \n",
      "iteracion 36 : costo 0.597770379887 \n",
      "iteracion 37 : costo 0.595076441774 \n",
      "iteracion 38 : costo 0.592398295699 \n",
      "iteracion 39 : costo 0.589735863108 \n",
      "iteracion 40 : costo 0.587089065984 \n",
      "iteracion 41 : costo 0.584457826704 \n",
      "iteracion 42 : costo 0.581842067943 \n",
      "iteracion 43 : costo 0.579241712603 \n",
      "iteracion 44 : costo 0.576656683766 \n",
      "iteracion 45 : costo 0.574086904661 \n",
      "iteracion 46 : costo 0.571532298638 \n",
      "iteracion 47 : costo 0.568992789155 \n",
      "iteracion 48 : costo 0.566468299767 \n",
      "iteracion 49 : costo 0.56395875412 \n",
      "iteracion 50 : costo 0.561464075948 \n",
      "iteracion 51 : costo 0.558984189069 \n",
      "iteracion 52 : costo 0.556519017389 \n",
      "iteracion 53 : costo 0.5540684849 \n",
      "iteracion 54 : costo 0.551632515681 \n",
      "iteracion 55 : costo 0.549211033901 \n",
      "iteracion 56 : costo 0.546803963824 \n",
      "iteracion 57 : costo 0.544411229807 \n",
      "iteracion 58 : costo 0.542032756304 \n",
      "iteracion 59 : costo 0.539668467871 \n",
      "iteracion 60 : costo 0.537318289169 \n",
      "iteracion 61 : costo 0.534982144962 \n",
      "iteracion 62 : costo 0.532659960127 \n",
      "iteracion 63 : costo 0.530351659654 \n",
      "iteracion 64 : costo 0.528057168646 \n",
      "iteracion 65 : costo 0.525776412328 \n",
      "iteracion 66 : costo 0.523509316047 \n",
      "iteracion 67 : costo 0.521255805275 \n",
      "iteracion 68 : costo 0.519015805612 \n",
      "iteracion 69 : costo 0.516789242791 \n",
      "iteracion 70 : costo 0.514576042678 \n",
      "iteracion 71 : costo 0.512376131281 \n",
      "iteracion 72 : costo 0.510189434745 \n",
      "iteracion 73 : costo 0.508015879361 \n",
      "iteracion 74 : costo 0.505855391568 \n",
      "iteracion 75 : costo 0.503707897955 \n",
      "iteracion 76 : costo 0.501573325264 \n",
      "iteracion 77 : costo 0.499451600397 \n",
      "iteracion 78 : costo 0.497342650411 \n",
      "iteracion 79 : costo 0.495246402531 \n",
      "iteracion 80 : costo 0.493162784143 \n",
      "iteracion 81 : costo 0.491091722808 \n",
      "iteracion 82 : costo 0.489033146253 \n",
      "iteracion 83 : costo 0.486986982386 \n",
      "iteracion 84 : costo 0.484953159289 \n",
      "iteracion 85 : costo 0.482931605226 \n",
      "iteracion 86 : costo 0.480922248648 \n",
      "iteracion 87 : costo 0.47892501819 \n",
      "iteracion 88 : costo 0.476939842679 \n",
      "iteracion 89 : costo 0.474966651135 \n",
      "iteracion 90 : costo 0.473005372771 \n",
      "iteracion 91 : costo 0.471055937004 \n",
      "iteracion 92 : costo 0.46911827345 \n",
      "iteracion 93 : costo 0.467192311928 \n",
      "iteracion 94 : costo 0.465277982467 \n",
      "iteracion 95 : costo 0.463375215306 \n",
      "iteracion 96 : costo 0.461483940895 \n",
      "iteracion 97 : costo 0.459604089902 \n",
      "iteracion 98 : costo 0.457735593213 \n",
      "iteracion 99 : costo 0.455878381933 \n",
      "batch  5\n",
      "iteracion 1 : costo 0.742718927756 \n",
      "iteracion 2 : costo 0.739085007575 \n",
      "iteracion 3 : costo 0.735508559972 \n",
      "iteracion 4 : costo 0.73197830031 \n",
      "iteracion 5 : costo 0.728486336671 \n",
      "iteracion 6 : costo 0.725027146736 \n",
      "iteracion 7 : costo 0.72159686087 \n",
      "iteracion 8 : costo 0.718192760773 \n",
      "iteracion 9 : costo 0.714812929421 \n",
      "iteracion 10 : costo 0.711456006974 \n",
      "iteracion 11 : costo 0.708121020762 \n",
      "iteracion 12 : costo 0.704807266977 \n",
      "iteracion 13 : costo 0.701514228409 \n",
      "iteracion 14 : costo 0.698241517293 \n",
      "iteracion 15 : costo 0.694988835612 \n",
      "iteracion 16 : costo 0.691755947553 \n",
      "iteracion 17 : costo 0.688542660391 \n",
      "iteracion 18 : costo 0.685348811239 \n",
      "iteracion 19 : costo 0.682174257858 \n",
      "iteracion 20 : costo 0.679018872289 \n",
      "iteracion 21 : costo 0.675882536449 \n",
      "iteracion 22 : costo 0.672765139068 \n",
      "iteracion 23 : costo 0.669666573583 \n",
      "iteracion 24 : costo 0.666586736672 \n",
      "iteracion 25 : costo 0.663525527242 \n",
      "iteracion 26 : costo 0.660482845734 \n",
      "iteracion 27 : costo 0.657458593644 \n",
      "iteracion 28 : costo 0.654452673185 \n",
      "iteracion 29 : costo 0.651464987069 \n",
      "iteracion 30 : costo 0.648495438346 \n",
      "iteracion 31 : costo 0.645543930304 \n",
      "iteracion 32 : costo 0.642610366398 \n",
      "iteracion 33 : costo 0.639694650205 \n",
      "iteracion 34 : costo 0.636796685395 \n",
      "iteracion 35 : costo 0.633916375712 \n",
      "iteracion 36 : costo 0.631053624971 \n",
      "iteracion 37 : costo 0.628208337047 \n",
      "iteracion 38 : costo 0.62538041588 \n",
      "iteracion 39 : costo 0.622569765479 \n",
      "iteracion 40 : costo 0.619776289923 \n",
      "iteracion 41 : costo 0.616999893371 \n",
      "iteracion 42 : costo 0.614240480066 \n",
      "iteracion 43 : costo 0.611497954345 \n",
      "iteracion 44 : costo 0.608772220647 \n",
      "iteracion 45 : costo 0.606063183519 \n",
      "iteracion 46 : costo 0.603370747626 \n",
      "iteracion 47 : costo 0.600694817759 \n",
      "iteracion 48 : costo 0.598035298845 \n",
      "iteracion 49 : costo 0.595392095953 \n",
      "iteracion 50 : costo 0.592765114302 \n",
      "iteracion 51 : costo 0.590154259272 \n",
      "iteracion 52 : costo 0.587559436409 \n",
      "iteracion 53 : costo 0.584980551437 \n",
      "iteracion 54 : costo 0.582417510259 \n",
      "iteracion 55 : costo 0.579870218974 \n",
      "iteracion 56 : costo 0.577338583875 \n",
      "iteracion 57 : costo 0.574822511463 \n",
      "iteracion 58 : costo 0.572321908454 \n",
      "iteracion 59 : costo 0.569836681781 \n",
      "iteracion 60 : costo 0.567366738607 \n",
      "iteracion 61 : costo 0.564911986329 \n",
      "iteracion 62 : costo 0.562472332585 \n",
      "iteracion 63 : costo 0.56004768526 \n",
      "iteracion 64 : costo 0.557637952495 \n",
      "iteracion 65 : costo 0.555243042689 \n",
      "iteracion 66 : costo 0.552862864511 \n",
      "iteracion 67 : costo 0.5504973269 \n",
      "iteracion 68 : costo 0.548146339076 \n",
      "iteracion 69 : costo 0.545809810541 \n",
      "iteracion 70 : costo 0.543487651089 \n",
      "iteracion 71 : costo 0.54117977081 \n",
      "iteracion 72 : costo 0.538886080092 \n",
      "iteracion 73 : costo 0.536606489633 \n",
      "iteracion 74 : costo 0.534340910439 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracion 75 : costo 0.532089253835 \n",
      "iteracion 76 : costo 0.529851431464 \n",
      "iteracion 77 : costo 0.527627355297 \n",
      "iteracion 78 : costo 0.525416937635 \n",
      "iteracion 79 : costo 0.523220091111 \n",
      "iteracion 80 : costo 0.521036728701 \n",
      "iteracion 81 : costo 0.51886676372 \n",
      "iteracion 82 : costo 0.516710109834 \n",
      "iteracion 83 : costo 0.514566681056 \n",
      "iteracion 84 : costo 0.512436391756 \n",
      "iteracion 85 : costo 0.510319156663 \n",
      "iteracion 86 : costo 0.508214890867 \n",
      "iteracion 87 : costo 0.506123509822 \n",
      "iteracion 88 : costo 0.504044929353 \n",
      "iteracion 89 : costo 0.501979065655 \n",
      "iteracion 90 : costo 0.499925835299 \n",
      "iteracion 91 : costo 0.497885155233 \n",
      "iteracion 92 : costo 0.495856942787 \n",
      "iteracion 93 : costo 0.493841115671 \n",
      "iteracion 94 : costo 0.491837591986 \n",
      "iteracion 95 : costo 0.489846290217 \n",
      "iteracion 96 : costo 0.487867129241 \n",
      "iteracion 97 : costo 0.48590002833 \n",
      "iteracion 98 : costo 0.483944907149 \n",
      "iteracion 99 : costo 0.482001685761 \n",
      "batch  6\n",
      "iteracion 1 : costo 0.88006372092 \n",
      "iteracion 2 : costo 0.86967206662 \n",
      "iteracion 3 : costo 0.861160073255 \n",
      "iteracion 4 : costo 0.854015184717 \n",
      "iteracion 5 : costo 0.847862229258 \n",
      "iteracion 6 : costo 0.842428437461 \n",
      "iteracion 7 : costo 0.8375164189 \n",
      "iteracion 8 : costo 0.832983791806 \n",
      "iteracion 9 : costo 0.828728078646 \n",
      "iteracion 10 : costo 0.824675630772 \n",
      "iteracion 11 : costo 0.820773568924 \n",
      "iteracion 12 : costo 0.816983948603 \n",
      "iteracion 13 : costo 0.813279550897 \n",
      "iteracion 14 : costo 0.809640853073 \n",
      "iteracion 15 : costo 0.806053851696 \n",
      "iteracion 16 : costo 0.802508499988 \n",
      "iteracion 17 : costo 0.798997586872 \n",
      "iteracion 18 : costo 0.795515933222 \n",
      "iteracion 19 : costo 0.792059815716 \n",
      "iteracion 20 : costo 0.788626553927 \n",
      "iteracion 21 : costo 0.785214214438 \n",
      "iteracion 22 : costo 0.781821398841 \n",
      "iteracion 23 : costo 0.778447091849 \n",
      "iteracion 24 : costo 0.775090552486 \n",
      "iteracion 25 : costo 0.771751236149 \n",
      "iteracion 26 : costo 0.768428738785 \n",
      "iteracion 27 : costo 0.765122756907 \n",
      "iteracion 28 : costo 0.761833058975 \n",
      "iteracion 29 : costo 0.758559464895 \n",
      "iteracion 30 : costo 0.75530183135 \n",
      "iteracion 31 : costo 0.752060041298 \n",
      "iteracion 32 : costo 0.748833996461 \n",
      "iteracion 33 : costo 0.745623611947 \n",
      "iteracion 34 : costo 0.742428812407 \n",
      "iteracion 35 : costo 0.739249529286 \n",
      "iteracion 36 : costo 0.736085698856 \n",
      "iteracion 37 : costo 0.732937260813 \n",
      "iteracion 38 : costo 0.729804157276 \n",
      "iteracion 39 : costo 0.726686332068 \n",
      "iteracion 40 : costo 0.723583730206 \n",
      "iteracion 41 : costo 0.720496297536 \n",
      "iteracion 42 : costo 0.717423980476 \n",
      "iteracion 43 : costo 0.714366725827 \n",
      "iteracion 44 : costo 0.711324480645 \n",
      "iteracion 45 : costo 0.708297192145 \n",
      "iteracion 46 : costo 0.705284807638 \n",
      "iteracion 47 : costo 0.702287274482 \n",
      "iteracion 48 : costo 0.69930454005 \n",
      "iteracion 49 : costo 0.696336551706 \n",
      "iteracion 50 : costo 0.693383256793 \n",
      "iteracion 51 : costo 0.690444602616 \n",
      "iteracion 52 : costo 0.687520536439 \n",
      "iteracion 53 : costo 0.684611005481 \n",
      "iteracion 54 : costo 0.681715956908 \n",
      "iteracion 55 : costo 0.678835337837 \n",
      "iteracion 56 : costo 0.675969095332 \n",
      "iteracion 57 : costo 0.673117176404 \n",
      "iteracion 58 : costo 0.670279528015 \n",
      "iteracion 59 : costo 0.667456097072 \n",
      "iteracion 60 : costo 0.664646830435 \n",
      "iteracion 61 : costo 0.661851674914 \n",
      "iteracion 62 : costo 0.659070577272 \n",
      "iteracion 63 : costo 0.656303484227 \n",
      "iteracion 64 : costo 0.653550342449 \n",
      "iteracion 65 : costo 0.65081109857 \n",
      "iteracion 66 : costo 0.648085699177 \n",
      "iteracion 67 : costo 0.64537409082 \n",
      "iteracion 68 : costo 0.642676220011 \n",
      "iteracion 69 : costo 0.639992033226 \n",
      "iteracion 70 : costo 0.637321476906 \n",
      "iteracion 71 : costo 0.634664497462 \n",
      "iteracion 72 : costo 0.632021041273 \n",
      "iteracion 73 : costo 0.629391054692 \n",
      "iteracion 74 : costo 0.626774484045 \n",
      "iteracion 75 : costo 0.624171275632 \n",
      "iteracion 76 : costo 0.621581375734 \n",
      "iteracion 77 : costo 0.619004730609 \n",
      "iteracion 78 : costo 0.616441286501 \n",
      "iteracion 79 : costo 0.613890989633 \n",
      "iteracion 80 : costo 0.611353786219 \n",
      "iteracion 81 : costo 0.608829622459 \n",
      "iteracion 82 : costo 0.606318444545 \n",
      "iteracion 83 : costo 0.60382019866 \n",
      "iteracion 84 : costo 0.601334830985 \n",
      "iteracion 85 : costo 0.598862287696 \n",
      "iteracion 86 : costo 0.596402514968 \n",
      "iteracion 87 : costo 0.593955458981 \n",
      "iteracion 88 : costo 0.591521065917 \n",
      "iteracion 89 : costo 0.589099281964 \n",
      "iteracion 90 : costo 0.58669005332 \n",
      "iteracion 91 : costo 0.584293326193 \n",
      "iteracion 92 : costo 0.581909046806 \n",
      "iteracion 93 : costo 0.579537161396 \n",
      "iteracion 94 : costo 0.577177616218 \n",
      "iteracion 95 : costo 0.574830357549 \n",
      "iteracion 96 : costo 0.572495331688 \n",
      "iteracion 97 : costo 0.570172484958 \n",
      "iteracion 98 : costo 0.567861763711 \n",
      "iteracion 99 : costo 0.565563114327 \n",
      "batch  7\n",
      "iteracion 1 : costo 0.789183809861 \n",
      "iteracion 2 : costo 0.784864055514 \n",
      "iteracion 3 : costo 0.780652418416 \n",
      "iteracion 4 : costo 0.776524434744 \n",
      "iteracion 5 : costo 0.772462587406 \n",
      "iteracion 6 : costo 0.768454344324 \n",
      "iteracion 7 : costo 0.764490743523 \n",
      "iteracion 8 : costo 0.760565375588 \n",
      "iteracion 9 : costo 0.756673653626 \n",
      "iteracion 10 : costo 0.752812290514 \n",
      "iteracion 11 : costo 0.748978925159 \n",
      "iteracion 12 : costo 0.745171855666 \n",
      "iteracion 13 : costo 0.741389849038 \n",
      "iteracion 14 : costo 0.737632005591 \n",
      "iteracion 15 : costo 0.733897662435 \n",
      "iteracion 16 : costo 0.730186324808 \n",
      "iteracion 17 : costo 0.726497617262 \n",
      "iteracion 18 : costo 0.722831248975 \n",
      "iteracion 19 : costo 0.719186989116 \n",
      "iteracion 20 : costo 0.715564649353 \n",
      "iteracion 21 : costo 0.711964071445 \n",
      "iteracion 22 : costo 0.708385118431 \n",
      "iteracion 23 : costo 0.704827668386 \n",
      "iteracion 24 : costo 0.701291609985 \n",
      "iteracion 25 : costo 0.697776839369 \n",
      "iteracion 26 : costo 0.694283257909 \n",
      "iteracion 27 : costo 0.69081077063 \n",
      "iteracion 28 : costo 0.687359285089 \n",
      "iteracion 29 : costo 0.683928710579 \n",
      "iteracion 30 : costo 0.680518957566 \n",
      "iteracion 31 : costo 0.677129937288 \n",
      "iteracion 32 : costo 0.67376156147 \n",
      "iteracion 33 : costo 0.670413742121 \n",
      "iteracion 34 : costo 0.667086391393 \n",
      "iteracion 35 : costo 0.663779421475 \n",
      "iteracion 36 : costo 0.660492744525 \n",
      "iteracion 37 : costo 0.657226272614 \n",
      "iteracion 38 : costo 0.65397991769 \n",
      "iteracion 39 : costo 0.650753591554 \n",
      "iteracion 40 : costo 0.64754720584 \n",
      "iteracion 41 : costo 0.644360672005 \n",
      "iteracion 42 : costo 0.641193901315 \n",
      "iteracion 43 : costo 0.638046804844 \n",
      "iteracion 44 : costo 0.634919293468 \n",
      "iteracion 45 : costo 0.631811277866 \n",
      "iteracion 46 : costo 0.628722668514 \n",
      "iteracion 47 : costo 0.62565337569 \n",
      "iteracion 48 : costo 0.622603309473 \n",
      "iteracion 49 : costo 0.619572379745 \n",
      "iteracion 50 : costo 0.616560496193 \n",
      "iteracion 51 : costo 0.61356756831 \n",
      "iteracion 52 : costo 0.610593505401 \n",
      "iteracion 53 : costo 0.607638216585 \n",
      "iteracion 54 : costo 0.604701610796 \n",
      "iteracion 55 : costo 0.601783596791 \n",
      "iteracion 56 : costo 0.598884083152 \n",
      "iteracion 57 : costo 0.59600297829 \n",
      "iteracion 58 : costo 0.59314019045 \n",
      "iteracion 59 : costo 0.590295627718 \n",
      "iteracion 60 : costo 0.587469198021 \n",
      "iteracion 61 : costo 0.584660809138 \n",
      "iteracion 62 : costo 0.581870368704 \n",
      "iteracion 63 : costo 0.579097784212 \n",
      "iteracion 64 : costo 0.576342963024 \n",
      "iteracion 65 : costo 0.573605812374 \n",
      "iteracion 66 : costo 0.570886239378 \n",
      "iteracion 67 : costo 0.568184151035 \n",
      "iteracion 68 : costo 0.565499454239 \n",
      "iteracion 69 : costo 0.562832055782 \n",
      "iteracion 70 : costo 0.560181862365 \n",
      "iteracion 71 : costo 0.557548780601 \n",
      "iteracion 72 : costo 0.554932717028 \n",
      "iteracion 73 : costo 0.552333578109 \n",
      "iteracion 74 : costo 0.549751270247 \n",
      "iteracion 75 : costo 0.547185699789 \n",
      "iteracion 76 : costo 0.544636773035 \n",
      "iteracion 77 : costo 0.542104396245 \n",
      "iteracion 78 : costo 0.53958847565 \n",
      "iteracion 79 : costo 0.537088917456 \n",
      "iteracion 80 : costo 0.534605627859 \n",
      "iteracion 81 : costo 0.532138513044 \n",
      "iteracion 82 : costo 0.529687479205 \n",
      "iteracion 83 : costo 0.527252432543 \n",
      "iteracion 84 : costo 0.524833279281 \n",
      "iteracion 85 : costo 0.522429925674 \n",
      "iteracion 86 : costo 0.520042278011 \n",
      "iteracion 87 : costo 0.51767024263 \n",
      "iteracion 88 : costo 0.515313725927 \n",
      "iteracion 89 : costo 0.512972634358 \n",
      "iteracion 90 : costo 0.510646874459 \n",
      "iteracion 91 : costo 0.508336352843 \n",
      "iteracion 92 : costo 0.506040976219 \n",
      "iteracion 93 : costo 0.503760651395 \n",
      "iteracion 94 : costo 0.50149528529 \n",
      "iteracion 95 : costo 0.49924478494 \n",
      "iteracion 96 : costo 0.49700905751 \n",
      "iteracion 97 : costo 0.4947880103 \n",
      "iteracion 98 : costo 0.492581550757 \n",
      "iteracion 99 : costo 0.490389586481 \n",
      "batch  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracion 1 : costo 0.798004468963 \n",
      "iteracion 2 : costo 0.793988984987 \n",
      "iteracion 3 : costo 0.790086726355 \n",
      "iteracion 4 : costo 0.786270054426 \n",
      "iteracion 5 : costo 0.782519479985 \n",
      "iteracion 6 : costo 0.778821271602 \n",
      "iteracion 7 : costo 0.775165757942 \n",
      "iteracion 8 : costo 0.771546126089 \n",
      "iteracion 9 : costo 0.767957572879 \n",
      "iteracion 10 : costo 0.764396706631 \n",
      "iteracion 11 : costo 0.760861126032 \n",
      "iteracion 12 : costo 0.757349124091 \n",
      "iteracion 13 : costo 0.753859480232 \n",
      "iteracion 14 : costo 0.750391314425 \n",
      "iteracion 15 : costo 0.746943984916 \n",
      "iteracion 16 : costo 0.743517016586 \n",
      "iteracion 17 : costo 0.740110050786 \n",
      "iteracion 18 : costo 0.736722810236 \n",
      "iteracion 19 : costo 0.733355074481 \n",
      "iteracion 20 : costo 0.730006662727 \n",
      "iteracion 21 : costo 0.726677421854 \n",
      "iteracion 22 : costo 0.723367218043 \n",
      "iteracion 23 : costo 0.720075930932 \n",
      "iteracion 24 : costo 0.716803449535 \n",
      "iteracion 25 : costo 0.713549669403 \n",
      "iteracion 26 : costo 0.710314490642 \n",
      "iteracion 27 : costo 0.707097816528 \n",
      "iteracion 28 : costo 0.703899552555 \n",
      "iteracion 29 : costo 0.700719605763 \n",
      "iteracion 30 : costo 0.697557884277 \n",
      "iteracion 31 : costo 0.694414296987 \n",
      "iteracion 32 : costo 0.691288753327 \n",
      "iteracion 33 : costo 0.688181163123 \n",
      "iteracion 34 : costo 0.685091436493 \n",
      "iteracion 35 : costo 0.682019483773 \n",
      "iteracion 36 : costo 0.678965215471 \n",
      "iteracion 37 : costo 0.675928542242 \n",
      "iteracion 38 : costo 0.672909374863 \n",
      "iteracion 39 : costo 0.669907624225 \n",
      "iteracion 40 : costo 0.666923201328 \n",
      "iteracion 41 : costo 0.663956017277 \n",
      "iteracion 42 : costo 0.661005983285 \n",
      "iteracion 43 : costo 0.658073010676 \n",
      "iteracion 44 : costo 0.655157010886 \n",
      "iteracion 45 : costo 0.65225789547 \n",
      "iteracion 46 : costo 0.649375576106 \n",
      "iteracion 47 : costo 0.646509964601 \n",
      "iteracion 48 : costo 0.643660972898 \n",
      "iteracion 49 : costo 0.640828513077 \n",
      "iteracion 50 : costo 0.638012497366 \n",
      "iteracion 51 : costo 0.635212838147 \n",
      "iteracion 52 : costo 0.632429447956 \n",
      "iteracion 53 : costo 0.629662239494 \n",
      "iteracion 54 : costo 0.62691112563 \n",
      "iteracion 55 : costo 0.624176019411 \n",
      "iteracion 56 : costo 0.621456834058 \n",
      "iteracion 57 : costo 0.618753482983 \n",
      "iteracion 58 : costo 0.616065879785 \n",
      "iteracion 59 : costo 0.613393938259 \n",
      "iteracion 60 : costo 0.610737572401 \n",
      "iteracion 61 : costo 0.608096696414 \n",
      "iteracion 62 : costo 0.605471224709 \n",
      "iteracion 63 : costo 0.602861071912 \n",
      "iteracion 64 : costo 0.60026615287 \n",
      "iteracion 65 : costo 0.597686382653 \n",
      "iteracion 66 : costo 0.59512167656 \n",
      "iteracion 67 : costo 0.592571950121 \n",
      "iteracion 68 : costo 0.590037119104 \n",
      "iteracion 69 : costo 0.587517099518 \n",
      "iteracion 70 : costo 0.585011807616 \n",
      "iteracion 71 : costo 0.582521159899 \n",
      "iteracion 72 : costo 0.580045073121 \n",
      "iteracion 73 : costo 0.577583464292 \n",
      "iteracion 74 : costo 0.575136250679 \n",
      "iteracion 75 : costo 0.572703349816 \n",
      "iteracion 76 : costo 0.570284679499 \n",
      "iteracion 77 : costo 0.567880157795 \n",
      "iteracion 78 : costo 0.565489703043 \n",
      "iteracion 79 : costo 0.563113233859 \n",
      "iteracion 80 : costo 0.560750669135 \n",
      "iteracion 81 : costo 0.558401928046 \n",
      "iteracion 82 : costo 0.556066930049 \n",
      "iteracion 83 : costo 0.553745594891 \n",
      "iteracion 84 : costo 0.551437842605 \n",
      "iteracion 85 : costo 0.549143593517 \n",
      "iteracion 86 : costo 0.546862768248 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-77c3bbdbb0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mX_train_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mX_train_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-333f37201c87>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_bias_col_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-333f37201c87>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-333f37201c87>\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpredicted_Y_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_examples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_Y_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredicted_Y_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-333f37201c87>\u001b[0m in \u001b[0;36mhypothesis\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# usamos la funcion sigmoidea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usando maxEnt\n",
    "# El entrenamiento se hizo por minibatch\n",
    "import scipy\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 50\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "cme = MaximunEntropy(learning_rate = 0.7,max_iter=100)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    doc_stream = stream_docs(path='shuffled_movie_data.csv')\n",
    "    for ii in range(int(45000/batch_size)):\n",
    "        X_train, y_train = get_minibatch(doc_stream,size=batch_size)\n",
    "        X_train = vect.transform(X_train)\n",
    "        y_train = np.asarray(y_train).ravel()\n",
    "        X_train_f = np.zeros(shape=(batch_size,2**21))\n",
    "        \n",
    "        cx = scipy.sparse.coo_matrix(X_train)\n",
    "        for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "            X_train_f[i][j] = v\n",
    "        \n",
    "        cme.train(X_train_f,y_train)\n",
    "        del X_train_f\n",
    "        print(\"batch \",ii)\n",
    "# si se interrumpe el entrenamiento sale error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyprind\n",
    "#pbar = pyprind.ProgBar(45)\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train_txt, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    X_train = vect.transform(X_train_txt)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    X_train = vect2.transform(X_train_txt)\n",
    "    clf2.partial_fit(X_train, y_train, classes=classes)\n",
    "    #pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your machine, it will take about 2-3 minutes to stream the documents and learn the weights for the logistic regression model to classify \"new\" movie reviews. Executing the preceding code, we used the first 45,000 movie reviews to train the classifier, which means that we have 5,000 reviews left for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.867\n",
      "Accuracy with new features: 0.871\n"
     ]
    }
   ],
   "source": [
    "X_test_txt, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test_txt)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))\n",
    "X_test = vect2.transform(X_test_txt)\n",
    "print('Accuracy with new features: %.3f' % clf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the predictive performance, an accuracy of ~87%, is quite \"reasonable\" given that we \"only\" used the default parameters and didn't do any hyperparameter optimization. \n",
    "\n",
    "After we estimated the model perfomance, let us use those last 5,000 test samples to update our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we successfully trained a model to predict the sentiment of a movie review. Unfortunately, if we'd close this IPython notebook at this point, we'd have to go through the whole learning process again and again if we'd want to make a prediction on \"new data.\"\n",
    "\n",
    "So, to reuse this model, we could use the [`pickle`](https://docs.python.org/3.5/library/pickle.html) module to \"serialize a Python object structure\". Or even better, we could use the [`joblib`](https://pypi.python.org/pypi/joblib) library, which handles large NumPy arrays more efficiently.\n",
    "\n",
    "To install:\n",
    "conda install -c anaconda joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./clf.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "if not os.path.exists('./pkl_objects'):\n",
    "    os.mkdir('./pkl_objects')\n",
    "    \n",
    "joblib.dump(vect, './vectorizer.pkl')\n",
    "joblib.dump(clf, './clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code above, we \"pickled\" the `HashingVectorizer` and the `SGDClassifier` so that we can re-use those objects later. However, `pickle` and `joblib` have a known issue with `pickling` objects or functions from a `__main__` block and we'd get an `AttributeError: Can't get attribute [x] on <module '__main__'>` if we'd unpickle it later. Thus, to pickle the `tokenizer` function, we can write it to a file and import it to get the `namespace` \"right\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tokenizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tokenizer.py\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    text = [w for w in text.split() if w not in stop]\n",
    "    tokenized = [porter.stem(w) for w in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tokenizer.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizer import tokenizer\n",
    "joblib.dump(tokenizer, './tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us restart this IPython notebook and check if the we can load our serialized objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "tokenizer = joblib.load('./tokenizer.pkl')\n",
    "vect = joblib.load('./vectorizer.pkl')\n",
    "clf = joblib.load('./clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the `tokenizer`, `HashingVectorizer`, and the tranined logistic regression model, we can use it to make predictions on new data, which can be useful, for example, if we'd want to embed our classifier into a web application -- a topic for another IPython notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I did not like this movie']\n",
    "X = vect.transform(example)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['I loved this movie']\n",
    "X = vect.transform(example)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
